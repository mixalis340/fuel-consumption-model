{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_33BeE3d9vQK"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkVh7Y2BCKTQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import interp1d\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance as xgb_plot_importance\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bsx4CUeEQb_"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0TAgFclyRZ3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('dataset_for_msc.csv')\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "df.sort_values(by='datetime', inplace=True)\n",
        "print(df.head())\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['fuel_volume_lit'] = df['fuel_volume_lit'].interpolate(method='linear')"
      ],
      "metadata": {
        "id": "LGlZO-RIxpMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "CAUYAVF6C7MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_series(df, x_col, y_col, title, xlabel, ylabel, color, grid=False, legend=False):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(df[x_col], df[y_col], label=ylabel, color=color)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    if grid:\n",
        "        plt.grid(True)\n",
        "    if legend:\n",
        "        plt.legend()\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HpLMCqOTDVZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_series(df, 'datetime', 'mileage_km', 'Mileage Over Time', 'Date', 'Mileage (km)', 'blue')\n",
        "plot_series(df, 'datetime', 'fuel_volume_lit', 'Fuel Volume Over Time', 'Date', 'Fuel Volume (liters)', 'green')\n",
        "plot_series(df, 'datetime', 'gross_vehicle_weight_kg', 'Gross Vehicle Weight Over Time', 'Date', 'Gross Vehicle Weight (kg)', 'red')"
      ],
      "metadata": {
        "id": "QjO8OrGiD9Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88taILxO_saJ"
      },
      "source": [
        "**Many missing values on mileage apperas to be when the truck is stationary (possible solution: fill the missing values with the previous mileage)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLSY_6pY_av5"
      },
      "outputs": [],
      "source": [
        "missing_mileage = df[df['mileage_km'].isnull()]\n",
        "\n",
        "# Check if speed_km_h is 0 for these rows\n",
        "speed_zero_missing_mileage = missing_mileage[missing_mileage['speed_km_h'] == 0]\n",
        "\n",
        "# Calculate the percentage of missing mileage where speed is 0\n",
        "percentage_speed_zero_missing = len(speed_zero_missing_mileage) / len(missing_mileage) * 100\n",
        "print(f\"Percentage of missing mileage where speed is 0: {percentage_speed_zero_missing:.2f}%\")\n",
        "\n",
        "df['mileage_km'] = df['mileage_km'].fillna(method='ffill')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['distance_covered_km'] = df['mileage_km'].diff().fillna(0)\n",
        "df['cumulative_distance_covered'] = df['distance_covered_km'].cumsum()\n",
        "df['smoothed_fuel'] = df['fuel_volume_lit'].rolling(window=15, min_periods=1).mean()"
      ],
      "metadata": {
        "id": "fKiUzECxE2Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_series(df, 'datetime', 'cumulative_distance_covered', 'Cumulative Distance Covered by Truck Over Time', 'Time', 'Cumulative Distance Covered (km)', 'blue', grid=True, legend=True)\n"
      ],
      "metadata": {
        "id": "KYZh7GiIFGYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df['elevation_m'] <10000]\n",
        "plt.figure(figsize=(5, 3))\n",
        "sns.boxplot(y=df['elevation_m'])\n",
        "plt.title('Box plot')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1FcV4x9qrVlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pG2LxsoEbun"
      },
      "source": [
        "# Truck total distance for 10 days"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "\n",
        "# Filter the data to only include entries from 01-06-22 to 11-06-22\n",
        "start_date = '2022-06-01'\n",
        "end_date = '2022-06-08'\n",
        "\n",
        "# Filter the dataframe for the date range\n",
        "filtered_df = df[(df['datetime'] >= start_date) & (df['datetime'] <= end_date)]\n",
        "\n",
        "# Calculate the cumulative distance covered for the filtered data\n",
        "filtered_df['distance_covered_km'] = filtered_df['mileage_km'].diff().fillna(0)\n",
        "filtered_df['cumulative_distance_covered'] = filtered_df['distance_covered_km'].cumsum()\n",
        "plot_series(filtered_df, 'datetime', 'cumulative_distance_covered', 'Cumulative Distance Covered by Truck from 01-06-2022 to 08-06-2022', 'Time', 'Cumulative Distance Covered (km)', 'blue', grid=True, legend=True)"
      ],
      "metadata": {
        "id": "QT0ryK2nFOAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5jwI_26H1a5"
      },
      "source": [
        "# Trend analysis for random date"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = '2022-06-06'\n",
        "end_date = '2022-06-07'\n",
        "\n",
        "\n",
        "filtered_df = df[(df['datetime'] >= start_date) & (df['datetime'] <= end_date)]\n",
        "\n",
        "filtered_df['distance_covered_km'] = filtered_df['mileage_km'].diff().fillna(0)\n",
        "filtered_df['cumulative_distance_covered'] = filtered_df['distance_covered_km'].cumsum()\n",
        "\n",
        "plot_series(filtered_df, 'datetime', 'cumulative_distance_covered', 'Cumulative Distance Covered by Truck from 06-06-2022 to 07-06-2022', 'Time', 'Cumulative Distance Covered (km)', 'blue', grid=True, legend=True)\n"
      ],
      "metadata": {
        "id": "Jr2MKBiSFmjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orHXp9G-Kau2"
      },
      "source": [
        "## Speed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_series(filtered_df, 'datetime', 'speed_km_h', 'Truck Speed from 06-06-2022 to 07-06-2022', 'Time', 'Speed', 'red', grid=True, legend=True)"
      ],
      "metadata": {
        "id": "jSFskD3AFyOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDdCYnkFKc4S"
      },
      "source": [
        "## Fuel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_series(filtered_df, 'datetime', 'fuel_volume_lit', 'Raw Fuel Levels', 'Time', 'Fuel (Liters)', 'green')\n",
        "plot_series(filtered_df, 'datetime', 'smoothed_fuel', 'Smoothed Fuel Levels', 'Time', 'Fuel (Liters)', 'blue')"
      ],
      "metadata": {
        "id": "U6_DK784F6SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBPjTWYQ-oqi"
      },
      "source": [
        "## Weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_series(filtered_df, 'datetime', 'gross_vehicle_weight_kg', 'Truck Weight', 'Time', 'Weight (kg)', 'brown')"
      ],
      "metadata": {
        "id": "Nh4lWnqpGmTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcKYFk5zOSZq"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_consecutive_nulls(df, feature, threshold):\n",
        "    \"\"\"\n",
        "    Removes consecutive rows where the specified feature has null values,\n",
        "    if the number of consecutive nulls meets or exceeds the threshold.\n",
        "\n",
        "    Parameters:\n",
        "    - df: Pandas DataFrame\n",
        "    - feature: Column name (string) to check for consecutive nulls\n",
        "    - threshold: Minimum number of consecutive nulls required for removal\n",
        "\n",
        "    Returns:\n",
        "    - A new DataFrame with consecutive null rows removed\n",
        "    \"\"\"\n",
        "    df = df.copy()  # Avoid modifying the original DataFrame\n",
        "\n",
        "    # Create a mask for null values\n",
        "    null_mask = df[feature].isnull()\n",
        "\n",
        "    # Identify consecutive groups of null values\n",
        "    df[\"group\"] = (null_mask != null_mask.shift()).cumsum()  # Assign group numbers\n",
        "\n",
        "    # Count only null values per group\n",
        "    null_group_counts = df[null_mask].groupby(\"group\")[feature].transform(\"size\")\n",
        "\n",
        "\n",
        "    # Remove rows where the entire group is null and meets the threshold\n",
        "    filtered_df = df[~((null_mask) & (null_group_counts >= threshold))].drop(columns=[\"group\"])\n",
        "\n",
        "    return filtered_df"
      ],
      "metadata": {
        "id": "YtxAjp8SGrVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = remove_consecutive_nulls(df, 'gross_vehicle_weight_kg', 200)"
      ],
      "metadata": {
        "id": "jpI67UUKGtfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_series(df_cleaned, 'datetime', 'gross_vehicle_weight_kg', 'Gross Vehicle Weight', 'Date', 'Gross Vehicle Weight (kg)', 'red')"
      ],
      "metadata": {
        "id": "k_4ekZFDGvZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2QfAc4Hh2Bt"
      },
      "source": [
        "## Interpolation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Linear Interpolation - Fills Missing Values\n",
        "df['linear_interp'] = df['gross_vehicle_weight_kg'].interpolate(method='linear')\n",
        "\n",
        "# Get valid (non-missing) data points for polynomial interpolation\n",
        "valid_data = df.dropna(subset=['gross_vehicle_weight_kg'])\n",
        "x_valid = valid_data.index.to_numpy()  # Ensure x values are numeric\n",
        "y_valid = valid_data['gross_vehicle_weight_kg'].to_numpy()\n",
        "\n",
        "# Apply Polynomial Interpolation (Quadratic)\n",
        "if len(x_valid) > 2:  # Need at least 3 points for quadratic interpolation\n",
        "    poly_interp = interp1d(x_valid, y_valid, kind='quadratic', fill_value=\"extrapolate\")\n",
        "    df['poly_interp'] = poly_interp(df.index.to_numpy())\n",
        "\n",
        "    # Fill only where data is missing\n",
        "    df['poly_interp'] = df['gross_vehicle_weight_kg'].combine_first(df['poly_interp'])\n",
        "else:\n",
        "    df['poly_interp'] = df['linear_interp']  # Fallback to linear if not enough points"
      ],
      "metadata": {
        "id": "jIn59YvzG3pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot original data\n",
        "plt.plot(df['datetime'], df['gross_vehicle_weight_kg'], 'o-', label='Original Data', color='red', alpha=0.6)\n",
        "\n",
        "# Plot linear interpolation\n",
        "plt.plot(df['datetime'], df['linear_interp'], '--', label='Linear Interpolation', color='blue', alpha=0.8)\n",
        "\n",
        "# Plot polynomial interpolation\n",
        "y_max = df['gross_vehicle_weight_kg'].max()\n",
        "df['poly_interp_clipped'] = df['poly_interp'].where(df['poly_interp'].between(0, y_max * 2), np.nan)\n",
        "plt.plot(df['datetime'], df['poly_interp_clipped'], '-.', label='Polynomial Interpolation', color='green', alpha=0.8)\n",
        "\n",
        "\n",
        "# Formatting\n",
        "plt.title('Gross Vehicle Weight Over Time with Interpolations')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Gross Vehicle Weight (kg)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eeaenzsxG5vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF1brBtkSN82"
      },
      "source": [
        "**Polynomial Intepolation causes extreme value out of the ordinary. So we will simply utilize Linear interpolation to predict our weights and further use for our experiments.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create more features that could be useful for the consumption model"
      ],
      "metadata": {
        "id": "PKP6tMoQUi-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
        "\n",
        "df['speed_m_s'] = df['speed_km_h'] * (5 / 18)\n",
        "df['speed_diff'] = df['speed_m_s'].diff()\n",
        "\n",
        "df['time_diff'] = df['datetime'].diff().dt.total_seconds()\n",
        "\n",
        "df['acceleration'] = df['speed_diff'] / df['time_diff']\n",
        "df['acceleration'] = df['acceleration'].replace([np.inf, -np.inf], np.nan)\n",
        "df['acceleration'] = df['acceleration'].fillna(0)"
      ],
      "metadata": {
        "id": "MOSEVmIMYWTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['elev_diff'] = df['elevation_m'].diff()"
      ],
      "metadata": {
        "id": "517wO_opf_sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"df_clean.csv\",index=False)"
      ],
      "metadata": {
        "id": "18CTjaw8HMJa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}