{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rX5b86eXyOPc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import interp1d\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import plot_importance as xgb_plot_importance\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffvBHDdoNJbz"
      },
      "outputs": [],
      "source": [
        "trips_df = pd.read_csv('all_trips.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trips_df.info()"
      ],
      "metadata": {
        "id": "9TjvKUzakpum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns = ['duration_min', 'mean_speed', 'mean_acceleration', 'max_acceleration',\n",
        "                     'mean_weight', 'elev_gain', 'distance_travelled', 'total_fuel_used_lit',\n",
        "                     'lit_per_100km']\n",
        "\n",
        "correlation_matrix = trips_df[numerical_columns].corr()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1)\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J8UzDpPazukW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check MAE on different subsets of data (before merging)"
      ],
      "metadata": {
        "id": "UCecngDYTSdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for source in ['30min', '2hr']:\n",
        "    subset = trips_df[trips_df['source'] == source]\n",
        "\n",
        "    if len(subset) < 5:\n",
        "        print(f\"Skipping {source} â€” too few samples ({len(subset)}).\")\n",
        "        continue\n",
        "\n",
        "    X = subset[['duration_min', 'mean_speed', 'mean_acceleration', 'max_acceleration',\n",
        "                'mean_weight', 'elev_gain', 'distance_travelled']]\n",
        "    y = subset['total_fuel_used_lit']\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('regressor', RandomForestRegressor(n_estimators=50, random_state=42))\n",
        "    ])\n",
        "\n",
        "    scores = cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
        "    print(f\"{source} MAE:\", -np.mean(scores))"
      ],
      "metadata": {
        "id": "C6iQr0Wz1IOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_distributions(X_train, X_test, y_train, y_test, feature_cols, target_col, source_col=None):\n",
        "    if source_col:\n",
        "      print(f\"\\nSource distribution by '{source_col}':\")\n",
        "      print(\"Train:\")\n",
        "      print(X_train[source_col].value_counts(normalize=True).sort_index())\n",
        "      print(\"\\nTest:\")\n",
        "      print(X_test[source_col].value_counts(normalize=True).sort_index())\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(5, 3))\n",
        "    sns.histplot(y_train, color='blue', label='Train', stat='density', bins=30)\n",
        "    sns.histplot(y_test, color='red', label='Test', stat='density', bins=30)\n",
        "    plt.title(f'Distribution of Target ({target_col}) in Train vs Test')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6275HdWG8nZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(X_train,X_test,y_train,y_test, name, model_tuple):\n",
        "    model, param_grid = model_tuple\n",
        "\n",
        "    # Normalize only if the model needs it\n",
        "    models_needing_scaling = (LinearRegression, Ridge, Lasso, ElasticNet,LinearSVR)\n",
        "    if isinstance(model, models_needing_scaling):\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('regressor', model)\n",
        "        ])\n",
        "        # Adjust param grid for pipeline\n",
        "        param_grid = {f'regressor__{k}': v for k, v in param_grid.items()}\n",
        "        estimator = pipeline\n",
        "    else:\n",
        "        estimator = model\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=estimator,\n",
        "        param_grid=param_grid,\n",
        "        cv=5,\n",
        "        scoring='neg_mean_squared_error',\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        error_score='raise'\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "    print(f\"{name} MAE: {mae:.4f}\")\n",
        "\n",
        "    plot_actual_vs_predicted(y_test, y_pred, name)\n",
        "\n",
        "    final_model = best_model.named_steps['regressor'] if isinstance(best_model, Pipeline) else best_model\n",
        "    plot_feature_importance(final_model, feature_cols, name)\n",
        "\n",
        "    return mae\n"
      ],
      "metadata": {
        "id": "fCGrlWWVk047"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importance(best_model, feature_cols, name,colors ='#8DA0CB'):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    if isinstance(best_model, xgb.XGBRegressor):\n",
        "        xgb.plot_importance(best_model, importance_type='gain', xlabel='Average Gain', height=0.5, grid=False, values_format=\"{v:.0f}\",\n",
        "                            color=colors if colors else 'C0')\n",
        "        plt.title(f'{name}: Feature Importance (XGBoost)')\n",
        "\n",
        "    elif hasattr(best_model, 'feature_importances_'):\n",
        "        importances = best_model.feature_importances_\n",
        "        indices = np.argsort(importances)[::-1]\n",
        "        feature_names = np.array(feature_cols)[indices]\n",
        "        bar_colors = colors if colors else sns.color_palette(\"Set2\", len(feature_names))\n",
        "        plt.barh(feature_names, importances[indices], height=0.5, color=bar_colors)\n",
        "        plt.xlabel('Feature Importance')\n",
        "        plt.title(f'{name}: Feature Importance')\n",
        "\n",
        "    elif hasattr(best_model, 'coef_'):\n",
        "        importances = best_model.coef_\n",
        "        indices = np.argsort(importances)\n",
        "        feature_names = np.array(feature_cols)[indices]\n",
        "        bar_colors = colors if colors else sns.color_palette(\"coolwarm\", len(feature_names))\n",
        "\n",
        "        plt.barh(feature_names, importances[indices], height=0.5, color=bar_colors)\n",
        "        plt.xlabel('Coefficient Value (Signed)')\n",
        "        plt.title(f'{name}: Signed Coefficient Importance')\n",
        "    else:\n",
        "        print(f\"Model {name} does not support feature importances.\")\n",
        "        return\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8jASubvC9k34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_actual_vs_predicted(y_test, y_pred, name):\n",
        "    indices = range(len(y_test))\n",
        "    plt.figure(figsize=(5, 3))\n",
        "    plt.plot(indices, y_test, color='#66C2A5', label='Actual', lw=2)\n",
        "    plt.plot(indices, y_pred, color='orange', label='Predicted', lw=2)\n",
        "    plt.title(f'{name}: Actual vs Predicted')\n",
        "    plt.xlabel('Example')\n",
        "    plt.ylabel('Fuel Used (liters)')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.grid(False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Xjn-vOb3-M0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_mae_comparison(results,title):\n",
        "\n",
        "    sorted_results = dict(sorted(results.items(), key=lambda item: item[1]))\n",
        "    model_names = list(sorted_results.keys())\n",
        "    mae_values = [sorted_results[model] for model in model_names]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    bars = plt.bar(model_names, mae_values, color = sns.color_palette(\"Accent\", len(model_names)))\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.ylabel('Mean Absolute Error', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
        "\n",
        "    for bar, mae in zip(bars, mae_values):\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2, yval + 0.5, f'{mae:.2f}', ha='center', va='bottom', fontsize=9)\n",
        "    plt.ylim(0, max(mae_values) * 1.15)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "VsTReS3FA8MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algorithms = {\n",
        "    'Random Forest': (\n",
        "        RandomForestRegressor(random_state=42),\n",
        "        {\n",
        "          'n_estimators': [100, 200],\n",
        "          'max_depth': [10, 20],\n",
        "          'min_samples_split': [2, 5],\n",
        "          'min_samples_leaf': [1, 2],\n",
        "          'max_features': ['sqrt', 'log2']\n",
        "        }\n",
        "    ),\n",
        "    'XGBoost': (\n",
        "        xgb.XGBRegressor(objective='reg:squarederror', random_state=42),\n",
        "        {\n",
        "          'n_estimators': [50, 100],\n",
        "          'max_depth': [3, 5, 7],\n",
        "          'learning_rate': [0.01, 0.1, 0.2]\n",
        "        }\n",
        "    ),\n",
        "     'Ridge Regression': (\n",
        "        Ridge(),\n",
        "        {\n",
        "            'alpha': [0.01, 0.1, 1.0, 10.0]\n",
        "        }\n",
        "    ),\n",
        "    'Lasso Regression': (\n",
        "        Lasso(max_iter=10000),\n",
        "        {\n",
        "            'alpha': [0.01, 0.1, 1.0, 10.0]\n",
        "        }\n",
        "    ),\n",
        "    'Gradient Boosting': (\n",
        "        GradientBoostingRegressor(random_state=42),\n",
        "        {\n",
        "          'n_estimators': [100, 200],\n",
        "          'learning_rate': [0.05, 0.1],\n",
        "          'max_depth': [3, 5, 7]\n",
        "        }\n",
        "    ),\n",
        "    'SVR': (\n",
        "    LinearSVR(),\n",
        "    {\n",
        "\n",
        "        'C': [0.1, 1],\n",
        "        'epsilon': [0.01, 0.1],\n",
        "        'max_iter': [1000,5000]\n",
        "\n",
        "    }\n",
        "),\n",
        "    'Decision Tree': (\n",
        "    DecisionTreeRegressor(random_state=42),\n",
        "    {\n",
        "        'max_depth': [3, 5, 10, None],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "    ),\n",
        "    'Linear Regression': (\n",
        "        LinearRegression(),\n",
        "        {}\n",
        "    ),\n",
        "     'Elastic Net': (\n",
        "        ElasticNet(max_iter=10000),\n",
        "        {\n",
        "            'alpha': [0.01, 0.1, 1.0],\n",
        "            'l1_ratio': [0.2, 0.5, 0.8]\n",
        "        }\n",
        "    )\n",
        "}\n",
        "\n",
        "\n",
        "feature_cols = ['duration_min', 'mean_speed', 'mean_acceleration', 'max_acceleration',\n",
        "                'mean_weight', 'elev_gain', 'distance_travelled']\n",
        "source_col = 'source'\n",
        "target_cols = ['total_fuel_used_lit','lit_per_100km']"
      ],
      "metadata": {
        "id": "hbCSpy3WC0OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(target,random_state=42,test_size=0.2,source_col = None):\n",
        "  X = trips_df[feature_cols].copy()\n",
        "  y = trips_df[target]\n",
        "\n",
        "  if source_col:\n",
        "    source = trips_df[source_col]\n",
        "  else:\n",
        "    source = None\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=random_state,\n",
        "    stratify=source if source_col else None\n",
        "  )\n",
        "\n",
        "  # if source_col:\n",
        "  #   X_train[source_col] = trips_df.loc[X_train.index, source_col]\n",
        "  #   X_test[source_col] = trips_df.loc[X_test.index, source_col]\n",
        "\n",
        "  plot_feature_distributions(X_train, X_test, y_train, y_test,\n",
        "                            feature_cols, target)\n",
        "\n",
        "\n",
        "  if source_col:\n",
        "    X_train = X_train.drop(columns=[source_col])\n",
        "    X_test = X_test.drop(columns=[source_col])\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "zimN6vj60n-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for target in target_cols:\n",
        "  results = {}\n",
        "  X_train, X_test, y_train, y_test = split_data(target)\n",
        "  for name, model in algorithms.items():\n",
        "      mae = train_and_evaluate(\n",
        "          X_train,\n",
        "          X_test,\n",
        "          y_train,\n",
        "          y_test,\n",
        "          name,\n",
        "          model\n",
        "      )\n",
        "      results[name] = mae\n",
        "  plot_mae_comparison(results,title=f\"MAE for target: {target}\")"
      ],
      "metadata": {
        "id": "rBno6v6jlivP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}